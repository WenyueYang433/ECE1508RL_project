--- Starting Training: GRU_DDQN 20251202_175724 ---
--- Hyperparameters ---
device: cuda
seed: 42
keep_top_n: 1000
min_ratings: 5
val_ratio: 0.2
data_rel_path: data/ml-latest-small
model_base: models/dqn_movielens.pt
model_finetuned: models/dqn_movielens_finetuned.pt
plot_summary: reports/figures/training_summary.png
model_arch: GRU
use_double_q: True
history_window: 10
hidden_dim: 256
dropout_rate: 0.2
buffer_size: 100000
batch_size: 512
learning_rate: 0.0001
gamma: 0.7
target_update: 500
base_n_updates: 10000
log_interval: 500
weight_decay: 1e-05
repeat_penalty: 1
popularity_penalty: 0.2
ft_n_steps: 2000
ft_batch_size: 32
ft_lr: 1e-05
ft_weight_decay: 1e-05
margin: 0.5
neg_per_pos: 5
use_candidates: True
candidate_k: 200
frac_candidate: 0.5
---- Architecture: GRU | Algorithm: DDQN ------
Total unique movies with ratings before filtering: 9724
Filtered to top 1000 movies. Remaining Ratings: 61256
Filtered users with < 5 ratings. Ratings dropped: 3
[RecoEnv] state_dim=20, n_actions=1000, repeat_penalty=1, popularity_penalty=0.2  
Mode=GRU 
train_transitions=96990, val_transitions=24250
[RecoEnv] reward(train): min=-1.426, max=0.997, mean=-0.118
Sample train rewards: [ 0.8776923  -0.5         0.97692305 -0.5         0.4076923  -0.5
  0.4823077  -0.5         0.90076923 -0.5         0.47230768 -0.5
  0.8676923  -0.5         0.47153845 -0.5         0.43461537 -0.5
  0.44846153 -0.5       ]
GRU_DQN(
  (gru): GRU(20, 256, batch_first=True)
  (fc1): Linear(in_features=256, out_features=256, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
  (fc_q): Linear(in_features=256, out_features=1000, bias=True)
)
[Agent] Preloaded 96990 transitions into replay buffer.
Loading Train/Validation Data...
--- Loading Data (Top 1000 movies, Min 5 ratings) ---
Total unique movies with ratings before filtering: 9724
Filtered to top 1000 movies. Remaining Ratings: 61256
Filtered users with < 5 ratings. Ratings dropped: 3
Starting training for 10000 steps...
Step  200 | Loss: 0.1304 | NDCG@10: 0.1462 | Avg Q: -0.071
--- Best Model Saved!
Step  400 | Loss: 0.1256 | NDCG@10: 0.1607 | Avg Q: -0.108
--- Best Model Saved!
Step  600 | Loss: 0.1257 | NDCG@10: 0.1700 | Avg Q: -0.051
--- Best Model Saved!
Step  800 | Loss: 0.1244 | NDCG@10: 0.1693 | Avg Q: 0.023
Step 1000 | Loss: 0.1230 | NDCG@10: 0.1438 | Avg Q: 0.025
Step 1200 | Loss: 0.1221 | NDCG@10: 0.1641 | Avg Q: 0.142
Step 1400 | Loss: 0.1210 | NDCG@10: 0.1778 | Avg Q: 0.150
--- Best Model Saved!
Step 1600 | Loss: 0.1203 | NDCG@10: 0.1550 | Avg Q: 0.250
Step 1800 | Loss: 0.1196 | NDCG@10: 0.1705 | Avg Q: 0.264
Step 2000 | Loss: 0.1191 | NDCG@10: 0.1518 | Avg Q: 0.277
Step 2200 | Loss: 0.1190 | NDCG@10: 0.1608 | Avg Q: 0.415
Step 2400 | Loss: 0.1186 | NDCG@10: 0.1657 | Avg Q: 0.401
Step 2600 | Loss: 0.1184 | NDCG@10: 0.1655 | Avg Q: 0.545
Step 2800 | Loss: 0.1181 | NDCG@10: 0.1803 | Avg Q: 0.552
--- Best Model Saved!
Step 3000 | Loss: 0.1177 | NDCG@10: 0.1714 | Avg Q: 0.540
Step 3200 | Loss: 0.1175 | NDCG@10: 0.1904 | Avg Q: 0.597
--- Best Model Saved!
Step 3400 | Loss: 0.1171 | NDCG@10: 0.2081 | Avg Q: 0.614
--- Best Model Saved!
Step 3600 | Loss: 0.1168 | NDCG@10: 0.1879 | Avg Q: 0.732
Step 3800 | Loss: 0.1165 | NDCG@10: 0.1883 | Avg Q: 0.709
Step 4000 | Loss: 0.1162 | NDCG@10: 0.1809 | Avg Q: 0.712
Step 4200 | Loss: 0.1160 | NDCG@10: 0.1898 | Avg Q: 0.779
Step 4400 | Loss: 0.1157 | NDCG@10: 0.1912 | Avg Q: 0.817
Step 4600 | Loss: 0.1155 | NDCG@10: 0.1910 | Avg Q: 0.831
Step 4800 | Loss: 0.1152 | NDCG@10: 0.1767 | Avg Q: 0.834
Step 5000 | Loss: 0.1149 | NDCG@10: 0.1805 | Avg Q: 0.840
Step 5200 | Loss: 0.1147 | NDCG@10: 0.1659 | Avg Q: 0.921
Step 5400 | Loss: 0.1145 | NDCG@10: 0.1918 | Avg Q: 0.901
Step 5600 | Loss: 0.1142 | NDCG@10: 0.1790 | Avg Q: 0.967
Step 5800 | Loss: 0.1140 | NDCG@10: 0.1618 | Avg Q: 0.909
Step 6000 | Loss: 0.1138 | NDCG@10: 0.1840 | Avg Q: 0.934
Step 6200 | Loss: 0.1136 | NDCG@10: 0.2007 | Avg Q: 0.993
Step 6400 | Loss: 0.1134 | NDCG@10: 0.1721 | Avg Q: 0.979
Step 6600 | Loss: 0.1132 | NDCG@10: 0.1556 | Avg Q: 1.064
Step 6800 | Loss: 0.1130 | NDCG@10: 0.1718 | Avg Q: 1.047
Step 7000 | Loss: 0.1129 | NDCG@10: 0.1604 | Avg Q: 1.049
Step 7200 | Loss: 0.1127 | NDCG@10: 0.1640 | Avg Q: 1.106
Step 7400 | Loss: 0.1125 | NDCG@10: 0.1855 | Avg Q: 1.097
Step 7600 | Loss: 0.1124 | NDCG@10: 0.1555 | Avg Q: 1.138
Step 7800 | Loss: 0.1123 | NDCG@10: 0.1839 | Avg Q: 1.142
Step 8000 | Loss: 0.1121 | NDCG@10: 0.1781 | Avg Q: 1.134
Step 8200 | Loss: 0.1120 | NDCG@10: 0.1523 | Avg Q: 1.168
Step 8400 | Loss: 0.1118 | NDCG@10: 0.1492 | Avg Q: 1.137
Step 8600 | Loss: 0.1117 | NDCG@10: 0.1479 | Avg Q: 1.194
Step 8800 | Loss: 0.1115 | NDCG@10: 0.1456 | Avg Q: 1.229
Step 9000 | Loss: 0.1114 | NDCG@10: 0.1551 | Avg Q: 1.216
Step 9200 | Loss: 0.1113 | NDCG@10: 0.1513 | Avg Q: 1.228
Step 9400 | Loss: 0.1112 | NDCG@10: 0.1726 | Avg Q: 1.247
Step 9600 | Loss: 0.1111 | NDCG@10: 0.1668 | Avg Q: 1.276
Step 9800 | Loss: 0.1110 | NDCG@10: 0.1789 | Avg Q: 1.316
Step 10000 | Loss: 0.1109 | NDCG@10: 0.1875 | Avg Q: 1.313
Training Complete!
 > Model saved to: /Users/lingyunguo/Documents/ECE1508RL_project/models/GRU_DDQN_20251202_175724.pt
 > Plot saved to:  /Users/lingyunguo/Documents/ECE1508RL_project/reports/figures/GRU_DDQN_20251202_175724.png
 > Log saved to:   /Users/lingyunguo/Documents/ECE1508RL_project/reports/training_log_20251202_175724.log
