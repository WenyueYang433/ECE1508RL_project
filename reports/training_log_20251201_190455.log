--- Starting Training: GRU_DDQN 20251201_190455 ---
--- Hyperparameters ---
device: cuda
seed: 42
keep_top_n: 1000
min_ratings: 5
val_ratio: 0.2
data_rel_path: data/ml-latest-small
model_base: models/dqn_movielens.pt
model_finetuned: models/dqn_movielens_finetuned.pt
plot_summary: reports/figures/training_summary.png
model_arch: GRU
use_double_q: True
history_window: 10
hidden_dim: 128
dropout_rate: 0.2
buffer_size: 100000
batch_size: 128
learning_rate: 0.0005
gamma: 0.9
target_update: 1000
base_n_updates: 10000
log_interval: 500
weight_decay: 1e-05
repeat_penalty: 1
popularity_penalty: 0.2
ft_n_steps: 2000
ft_batch_size: 32
ft_lr: 1e-05
ft_weight_decay: 1e-05
margin: 0.5
neg_per_pos: 5
use_candidates: True
candidate_k: 200
frac_candidate: 0.5
---- Architecture: GRU | Algorithm: DDQN ------
Total unique movies with ratings before filtering: 9724
Filtered to top 1000 movies. Remaining Ratings: 61256
Filtered users with < 5 ratings. Ratings dropped: 3
[RecoEnv] state_dim=20, n_actions=1000, repeat_penalty=1, popularity_penalty=0.2  
Mode=GRU 
train_transitions=96990, val_transitions=24252
[RecoEnv] reward(train): min=-1.426, max=0.997, mean=-0.118
Sample train rewards: [ 0.8776923  -0.5         0.4823077  -0.5         0.97692305 -0.5
  0.4076923  -0.5         0.90076923 -0.5         0.47230768 -0.5
  0.47153845 -0.5         0.8676923  -0.5         0.43384615 -0.5
  0.44846153 -0.5       ]
GRU_DQN(
  (gru): GRU(20, 128, batch_first=True)
  (fc1): Linear(in_features=128, out_features=128, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
  (fc_q): Linear(in_features=128, out_features=1000, bias=True)
)
[Agent] Preloaded 96990 transitions into replay buffer.
Loading Train/Validation Data...
--- Loading Data (Top 1000 movies, Min 5 ratings) ---
Total unique movies with ratings before filtering: 9724
Filtered to top 1000 movies. Remaining Ratings: 61256
Filtered users with < 5 ratings. Ratings dropped: 3
Starting training for 10000 steps...
Step  200 | Loss: 0.1311 | NDCG@10: 0.1724 | Avg Q: -0.076
--- Best Model Saved!
Step  400 | Loss: 0.1278 | NDCG@10: 0.1537 | Avg Q: -0.123
Step  600 | Loss: 0.1256 | NDCG@10: 0.1697 | Avg Q: -0.140
Step  800 | Loss: 0.1243 | NDCG@10: 0.2035 | Avg Q: -0.173
--- Best Model Saved!
Step 1000 | Loss: 0.1232 | NDCG@10: 0.1854 | Avg Q: -0.167
Step 1200 | Loss: 0.1248 | NDCG@10: 0.1166 | Avg Q: 0.064
Step 1400 | Loss: 0.1241 | NDCG@10: 0.1337 | Avg Q: 0.072
Step 1600 | Loss: 0.1232 | NDCG@10: 0.1611 | Avg Q: 0.085
Step 1800 | Loss: 0.1225 | NDCG@10: 0.2004 | Avg Q: 0.104
Step 2000 | Loss: 0.1219 | NDCG@10: 0.1690 | Avg Q: 0.071
Step 2200 | Loss: 0.1222 | NDCG@10: 0.1735 | Avg Q: 0.311
Step 2400 | Loss: 0.1217 | NDCG@10: 0.1837 | Avg Q: 0.289
Step 2600 | Loss: 0.1211 | NDCG@10: 0.1670 | Avg Q: 0.308
Step 2800 | Loss: 0.1205 | NDCG@10: 0.1814 | Avg Q: 0.271
Step 3000 | Loss: 0.1198 | NDCG@10: 0.1988 | Avg Q: 0.303
Step 3200 | Loss: 0.1202 | NDCG@10: 0.1896 | Avg Q: 0.642
Step 3400 | Loss: 0.1201 | NDCG@10: 0.2049 | Avg Q: 0.618
--- Best Model Saved!
Step 3600 | Loss: 0.1201 | NDCG@10: 0.2212 | Avg Q: 0.596
--- Best Model Saved!
Step 3800 | Loss: 0.1200 | NDCG@10: 0.2074 | Avg Q: 0.588
Step 4000 | Loss: 0.1196 | NDCG@10: 0.2301 | Avg Q: 0.608
--- Best Model Saved!
Step 4200 | Loss: 0.1204 | NDCG@10: 0.1815 | Avg Q: 1.035
Step 4400 | Loss: 0.1207 | NDCG@10: 0.1812 | Avg Q: 0.976
Step 4600 | Loss: 0.1209 | NDCG@10: 0.1766 | Avg Q: 0.973
Step 4800 | Loss: 0.1211 | NDCG@10: 0.1675 | Avg Q: 1.063
Step 5000 | Loss: 0.1211 | NDCG@10: 0.2214 | Avg Q: 1.039
Step 5200 | Loss: 0.1223 | NDCG@10: 0.1679 | Avg Q: 1.530
Step 5400 | Loss: 0.1229 | NDCG@10: 0.2040 | Avg Q: 1.430
Step 5600 | Loss: 0.1235 | NDCG@10: 0.1800 | Avg Q: 1.477
Step 5800 | Loss: 0.1240 | NDCG@10: 0.1890 | Avg Q: 1.468
Step 6000 | Loss: 0.1244 | NDCG@10: 0.1782 | Avg Q: 1.442
Step 6200 | Loss: 0.1256 | NDCG@10: 0.1961 | Avg Q: 1.883
Step 6400 | Loss: 0.1266 | NDCG@10: 0.1924 | Avg Q: 1.859
Step 6600 | Loss: 0.1272 | NDCG@10: 0.2193 | Avg Q: 1.895
Step 6800 | Loss: 0.1279 | NDCG@10: 0.2266 | Avg Q: 1.833
Step 7000 | Loss: 0.1284 | NDCG@10: 0.2217 | Avg Q: 1.896
Step 7200 | Loss: 0.1298 | NDCG@10: 0.2070 | Avg Q: 2.467
Step 7400 | Loss: 0.1309 | NDCG@10: 0.2129 | Avg Q: 2.435
Step 7600 | Loss: 0.1319 | NDCG@10: 0.2316 | Avg Q: 2.451
--- Best Model Saved!
Step 7800 | Loss: 0.1328 | NDCG@10: 0.2085 | Avg Q: 2.476
Step 8000 | Loss: 0.1335 | NDCG@10: 0.2263 | Avg Q: 2.413
Step 8200 | Loss: 0.1356 | NDCG@10: 0.2175 | Avg Q: 3.064
Step 8400 | Loss: 0.1371 | NDCG@10: 0.1811 | Avg Q: 3.035
Step 8600 | Loss: 0.1385 | NDCG@10: 0.2187 | Avg Q: 3.167
Step 8800 | Loss: 0.1397 | NDCG@10: 0.2047 | Avg Q: 3.076
Step 9000 | Loss: 0.1408 | NDCG@10: 0.1900 | Avg Q: 3.123
Step 9200 | Loss: 0.1436 | NDCG@10: 0.2122 | Avg Q: 4.047
Step 9400 | Loss: 0.1458 | NDCG@10: 0.1676 | Avg Q: 3.944
Step 9600 | Loss: 0.1478 | NDCG@10: 0.1761 | Avg Q: 4.044
Step 9800 | Loss: 0.1497 | NDCG@10: 0.1816 | Avg Q: 3.986
Step 10000 | Loss: 0.1515 | NDCG@10: 0.2090 | Avg Q: 3.970
Training Complete!
 > Model saved to: D:\Git\1508RL\ECE1508RL_project\models\GRU_DDQN_20251201_190455.pt
 > Plot saved to:  D:\Git\1508RL\ECE1508RL_project\reports\figures\GRU_DDQN_20251201_190455.png
 > Log saved to:   D:\Git\1508RL\ECE1508RL_project\reports\training_log_20251201_190455.log
